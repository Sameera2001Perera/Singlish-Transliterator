{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers torch datasets wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:20:08.641169Z","iopub.execute_input":"2024-11-28T20:20:08.641473Z","iopub.status.idle":"2024-11-28T20:20:17.913816Z","shell.execute_reply.started":"2024-11-28T20:20:08.641443Z","shell.execute_reply":"2024-11-28T20:20:17.912736Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\nfrom datasets import Dataset\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:20:17.915598Z","iopub.execute_input":"2024-11-28T20:20:17.915871Z","iopub.status.idle":"2024-11-28T20:20:36.345954Z","shell.execute_reply.started":"2024-11-28T20:20:17.915843Z","shell.execute_reply":"2024-11-28T20:20:36.345291Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def cleaning_sentence(sentence):\n    words = sentence.split()\n    words = [re.sub(r'[^\\u0D80-\\u0DFF\\s]', '', word).strip() for word in words]\n    words = [word for word in words if word != \"\"]\n\n    return \" \".join(words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:20:36.347237Z","iopub.execute_input":"2024-11-28T20:20:36.347563Z","iopub.status.idle":"2024-11-28T20:20:36.352399Z","shell.execute_reply.started":"2024-11-28T20:20:36.347535Z","shell.execute_reply":"2024-11-28T20:20:36.351379Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_path = \"/kaggle/input/dakshina-train/wiki-filt.train.text.shuf.txt\"\nvalidation_path = \"/kaggle/input/dakshina-valid/wiki-filt.valid.text.shuf.txt\"\n\ntraining_data = []\nwith open(train_path, \"r\", encoding=\"utf-8\") as file:\n    for line in file:\n        training_data.append(cleaning_sentence(line.strip()))\n    print('Training data processing completed!')\n    print(f'Total training data: {len(training_data)}')\n\nvalidation_data = []\nwith open(validation_path, \"r\", encoding=\"utf-8\") as file:\n    for line in file:\n        validation_data.append(cleaning_sentence(line.strip()))\n    print('Validation data processing completed!')\n    print(f'Total validation data: {len(validation_data)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:20:36.353436Z","iopub.execute_input":"2024-11-28T20:20:36.353737Z","iopub.status.idle":"2024-11-28T20:20:39.981156Z","shell.execute_reply.started":"2024-11-28T20:20:36.353692Z","shell.execute_reply":"2024-11-28T20:20:39.980253Z"}},"outputs":[{"name":"stdout","text":"Training data processing completed!\nTotal training data: 200629\nValidation data processing completed!\nTotal validation data: 28623\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model_name = \"Ransaka/sinhala-bert-medium-v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:20:49.152506Z","iopub.execute_input":"2024-11-28T20:20:49.152849Z","iopub.status.idle":"2024-11-28T20:20:52.894577Z","shell.execute_reply.started":"2024-11-28T20:20:49.152819Z","shell.execute_reply":"2024-11-28T20:20:52.893751Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/315 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28e844b7c3ce45d2aff3de34efbf1db7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/485k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8fe5383dc3741daaf056a8521218afa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/988k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"847fbfb27da0498cbcc3321058d10bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4850558ae94310b698faabcd48db72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/640 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2c94bff01746e8bc90d4c7df73ed16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/202M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92879c6adb534234ad0f89e55b521e6b"}},"metadata":{}},{"name":"stderr","text":"BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4790925a4bb8429d9a627463d60b90db"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_dataset = Dataset.from_dict({\"text\": training_data})\neval_dataset = Dataset.from_dict({\"text\": validation_data})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:20:57.132658Z","iopub.execute_input":"2024-11-28T20:20:57.133258Z","iopub.status.idle":"2024-11-28T20:20:57.848092Z","shell.execute_reply.started":"2024-11-28T20:20:57.133225Z","shell.execute_reply":"2024-11-28T20:20:57.847319Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:21:03.433358Z","iopub.execute_input":"2024-11-28T20:21:03.433707Z","iopub.status.idle":"2024-11-28T20:21:03.440416Z","shell.execute_reply.started":"2024-11-28T20:21:03.433679Z","shell.execute_reply":"2024-11-28T20:21:03.439350Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 200629\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\neval_dataset = eval_dataset.map(tokenize_function, batched=True)\n\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:21:10.753469Z","iopub.execute_input":"2024-11-28T20:21:10.754115Z","iopub.status.idle":"2024-11-28T20:21:46.822077Z","shell.execute_reply.started":"2024-11-28T20:21:10.754082Z","shell.execute_reply":"2024-11-28T20:21:46.821179Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200629 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc288611e6434735b27f8162005654b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28623 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8046bc4df3774ebc88cec99887fbc577"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"token = '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'\n!huggingface-cli login --token \"$token\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:21:46.848552Z","iopub.execute_input":"2024-11-28T20:21:46.848791Z","iopub.status.idle":"2024-11-28T20:21:48.428811Z","shell.execute_reply.started":"2024-11-28T20:21:46.848766Z","shell.execute_reply":"2024-11-28T20:21:48.427867Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./sinhala_bert_finetuned_12epoch\",\n    overwrite_output_dir=True,\n    push_to_hub=True,\n    hub_model_id=\"Sameera827/sinhala-bert-dakshina_finetuned_epoch12\",\n    num_train_epochs=12,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=16,\n    evaluation_strategy=\"epoch\",\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n)\n\ntrainer.train()\n\n\neval_results = trainer.evaluate()\nprint(\"Evaluation results:\", eval_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T20:21:54.293679Z","iopub.execute_input":"2024-11-28T20:21:54.294036Z","iopub.status.idle":"2024-11-29T07:07:23.896955Z","shell.execute_reply.started":"2024-11-28T20:21:54.294000Z","shell.execute_reply":"2024-11-29T07:07:23.896144Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111287128888926, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf05f59e4536463688c9226d20532aa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241128_202216-nhyow023</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lahirupj099-kaya/huggingface/runs/nhyow023' target=\"_blank\">./sinhala_bert_finetuned_12epoch</a></strong> to <a href='https://wandb.ai/lahirupj099-kaya/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lahirupj099-kaya/huggingface' target=\"_blank\">https://wandb.ai/lahirupj099-kaya/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lahirupj099-kaya/huggingface/runs/nhyow023' target=\"_blank\">https://wandb.ai/lahirupj099-kaya/huggingface/runs/nhyow023</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='37620' max='37620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [37620/37620 10:42:14, Epoch 12/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.305700</td>\n      <td>4.233554</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.123000</td>\n      <td>4.099900</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.008900</td>\n      <td>4.022184</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.892400</td>\n      <td>3.955532</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.804700</td>\n      <td>3.949266</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.730300</td>\n      <td>3.875835</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.666200</td>\n      <td>3.856209</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.637900</td>\n      <td>3.840752</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.605300</td>\n      <td>3.794821</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.530500</td>\n      <td>3.793829</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>3.532500</td>\n      <td>3.792052</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>3.511100</td>\n      <td>3.768847</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1789' max='1789' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1789/1789 02:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 3.775315046310425, 'eval_runtime': 167.8515, 'eval_samples_per_second': 170.526, 'eval_steps_per_second': 10.658, 'epoch': 12.0}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import math\nprint(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T07:21:49.178383Z","iopub.execute_input":"2024-11-29T07:21:49.178729Z","iopub.status.idle":"2024-11-29T07:21:49.185428Z","shell.execute_reply.started":"2024-11-29T07:21:49.178700Z","shell.execute_reply":"2024-11-29T07:21:49.184480Z"}},"outputs":[{"name":"stdout","text":">>> Perplexity: 43.61\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}